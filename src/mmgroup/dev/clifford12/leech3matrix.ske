/** @file leech_mod3.c
  File ``leech_mod3.c`` contains  functions for computing with
  symmetric matrices on the Leech lattice mod 3. 
*/

/*************************************************************************
** External references 
*************************************************************************/

/// @cond DO_NOT_DOCUMENT 
#include <string.h>
#include "mat24_functions.h"
#define MMGROUP_GENERATORS_INTERN
#include "mmgroup_generators.h"
#define CLIFFORD12_INTERN
#include "clifford12.h"
/// @endcond  


// %%EXPORT_KWD CLIFFORD12_API

// %%GEN h

/// @cond DO_NOT_DOCUMENT 


// %%GEN ch
#ifdef __cplusplus
extern "C" {
#endif
// %%GEN c


/*************************************************************************
*** Basic definitions
*************************************************************************/

/// @cond DO_NOT_DOCUMENT 


#define NEG_MASK_MOD3 0x3333333333333333ULL


#define REDUCE_MOD3(a) \
 (a) = (((a) + (((a) >> 2) & 0x1111111111111111ULL)) & NEG_MASK_MOD3)


#define REDUCE_FINAL_MOD3(a) \
 (a) +=  0x1111111111111111ULL; \
 (a) -= (~(a) >> 2) &  0x1111111111111111ULL; \
 (a) &= NEG_MASK_MOD3


#define EXPAND_3_15(a) \
    (a) = ((a) & 0xffffULL) \
        +  (((a) & 0xffff0000ULL) << 16); \
    (a) = ((a) & 0xff000000ffULL) \
        +  (((a) & 0xff000000ff00ULL) << 8); \
    (a) = ((a) & 0xf000f000f000fULL) \
        +  (((a) & 0xf000f000f000f0ULL) << 4); \
    (a) = ((a) & 0x303030303030303ULL) \
        +  (((a) & 0xc0c0c0c0c0c0c0cULL) << 2)


#define COMPRESS_15_3(a) \
    (a) = ((a) & 0x303030303030303ULL) \
        +  (((a) >> 2) & 0xc0c0c0c0c0c0c0cULL); \
    (a) = ((a) & 0xf000f000f000fULL) \
        +  (((a) >> 4) & 0xf000f000f000f0ULL); \
    (a) = ((a) & 0xff000000ffULL) \
        +  (((a) >> 8) & 0xff000000ff00ULL); \
    (a) = ((a) & 0xffffULL) \
        +  (((a) >> 16) & 0xffff0000ULL)


/// @endcond 

/*************************************************************************
*** Start of C code
*************************************************************************/

// %%WITH N_COL = 3



// %%EXPORT px
void leech3matrix_load_3(uint64_t *v, uint64_t *a)
{
    uint_fast32_t i, j = 0;
    for (i = 0; i < 24; ++i) {
        a[j] = v[i];
        a[j+1] = v[i] >> 32;
        EXPAND_3_15(a[j]);
        EXPAND_3_15(a[j+1]);
        a[j+1] &= 0xffffffffULL;
        // %%FOR* k in range(2, N_COL)
        a[i + %{k}] = 0;
        // %%END FOR
        j +=  %{N_COL};
    } 
}


void leech3matrix_load_15(uint64_t *v, uint64_t *a)
{
    uint_fast32_t i, j = 0;
    for (i = 0; i < 24; ++i) {
        a[j] = v[i];
        a[j + 1] = v[i + 1];
        REDUCE_MOD3(a[j]);
        REDUCE_MOD3(a[j + 1]);
        a[j + 1] &= 0xffffffffULL;
        // %%FOR* k in range(2, N_COL)
        a[i + %{k}] = 0;
        // %%END FOR
        j +=  %{N_COL};
    } 
}


static inline uint32_t pivot3(uint64_t *p_a, uint64_t *p_end, uint32_t column)
{
     
    uint64_t sign_pivot, sign, tmp;
    uint64_t  *p_pivot, *p_row;
    uint_fast32_t col_ofs = column >> 4, col_sh = (column & 15) << 2;

    for (p_pivot = p_a; p_pivot < p_end; p_pivot += %{N_COL}) {
        sign_pivot = (p_pivot[col_ofs] >> col_sh) + 1;
        if (sign_pivot & 2) goto pivot_found;
    }
    return 0;

pivot_found:
    ++sign_pivot;
    for (p_row = p_pivot + %{N_COL}; p_row < p_end; p_row += %{N_COL}) {
        sign =  (p_row[col_ofs] >> col_sh) + 1;
        if (sign & 2) {
            sign = (0 - ((sign + sign_pivot) & ONE)) & NEG_MASK_MOD3;
            // %%FOR* i in range(N_COL)
            p_row[%{i}] += (p_pivot[%{i}] ^ sign);
            REDUCE_MOD3(p_row[%{i}]);
            // %%END FOR
        }
    }

    // %%FOR* i in range(N_COL)
    tmp = p_a[%{i}]; p_a[%{i}] = p_pivot[%{i}]; p_pivot[%{i}] = tmp;
    // %%END FOR
    return %{N_COL};
}


// %%EXPORT px
void leech3matrix_echelon(uint64_t *a)
{
    uint64_t *p_a = a, *p_end = a +  %{int:24*N_COL};
    uint_fast32_t col;
    for (col = 0; col < 23; ++col) {
        p_a += pivot3(p_a, p_end, col);
    }
}

// %%EXPORT px
uint64_t leech3matrix_echelon_kernel_vector(uint64_t *a)
{
    uint64_t v[2][2], tmp;
    uint_fast32_t i, j =  %{int:22*N_COL};

    for (i = 0; i < 2; ++i) {
        v[i][0] =  COMPRESS_15_3(a[j]);
        tmp = COMPRESS_15_3(a[i+1]);
        v[i][1] = COMPRESS_15_3(a[j+1]);
        v[i][0] += (tmp & 0xffff) << 16;
        v[i][1] = (v[i][1] << 16) + (tmp >> 16);
        j += %{N_COL};
    }

    if (~v[0][0] || v[1][0]) return 0;
    REDUCE_FINAL_MOD3(v[1][1]);
    return short_3_reduce(xsp2co1_to_vect_mod3(v[1][1]));
}


void leech3matrix_sub_diag(uint64_t *a, uint64_t diag, uint32_t offset)
{
    uint_fast32_t col_ofs, col_sh;
    uint64_t *p_a, *p_end = a + 12 * %{N_COL};
    diag %= 3;
    if (diag == 0) return;
    diag = 3ULL - diag;
    for (p_a = a; p_a < p_end; p_a += %{N_COL}) {
        col_ofs = offset >> 4, col_sh = (offset & 15) << 2;
        p_a[col_ofs] += diag << col_sh;
        REDUCE_MOD3(p_a[col_ofs]);
        ++offset;
    }
}

// %%EXPORT px
uint64_t leech3matrix_kernel_vector(uint64_t *v, uint32_t p_in, uint32_t diag)
{
    uint64_t a[24 *  %{N_COL}];
    if (p_in == 15) leech3matrix_load_15(v, a);
    else if (p_in == 3) leech3matrix_load_3(v, a);
    else return 0;
    leech3matrix_sub_diag(a, diag, 0);
    leech3matrix_sub_diag(a, 2, 24);
    leech3matrix_echelon(a);
    return leech3matrix_echelon_kernel_vector(a);
}


// %%END WITH 


/*************************************************************************
*** End of of C code
*************************************************************************/


//  %%GEN h
/// @endcond  
//  %%GEN c



// %%GEN ch
#ifdef __cplusplus
}
#endif




