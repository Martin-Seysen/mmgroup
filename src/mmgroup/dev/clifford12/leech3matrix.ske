/** @file leech3matrix.c

  File ``leech3matrix.c`` contains  functions for computing with
  matrices corresponding to the part with tag 'A' of a vector
  of the representation of the monster modulo 3. Note that this
  part has a natural interpretation as a symmetric matrix on the
  Leech lattice.

  For these computations we deal with ``i0`` times ``i1``
  matrices ``m`` for ``i0 <= 24``, ``i1 <= 48``, Such a matrix
  is stored in an array ``a`` of integers of type ``uint64_t``
  of length 24 * 3. Here the entry ``m[i,j]`` is stored
  in ``a[3*i + j/16]``, bits ``4 * (j % 16),..., 4 * (j % 16) + 3``.
  We call ``a`` the **matrix mod 3** encoding of the matrix ``m``.

  Unless otherwise stated, we assume that the lower two bits of such
  a bit field have arbitrary values, and that the higher two bits
  of that bit field are zero.

  There are functions for loading such a matrix ``m`` from a
  vector in a representation of the  monster, for elechonization
  of ``m``, for computing the kernel of ``m`` etc.
*/

/*************************************************************************
** External references 
*************************************************************************/

/// @cond DO_NOT_DOCUMENT 
#include <string.h>
#include "mat24_functions.h"
#define MMGROUP_GENERATORS_INTERN
#include "mmgroup_generators.h"
#define CLIFFORD12_INTERN
#include "clifford12.h"
/// @endcond  



// %%GEN h

/// @cond DO_NOT_DOCUMENT 


// %%GEN ch
#ifdef __cplusplus
extern "C" {
#endif
// %%GEN c


/*************************************************************************
*** Basic definitions
*************************************************************************/

/// @cond DO_NOT_DOCUMENT 


#define NEG_MASK_MOD3 0x3333333333333333ULL


/** @brief Reduce a bit field of integers modulo 3

  We assume that an array of integers (mod 3) is stored in an
  integer ``a`` of type ``uint64_t``. Here each entry of that
  array is stored in a field of 4 bits.

  We assume that in each entry the lower 3 bits may be set, and
  we reduce each entry to a length of 2 bits. The result is stored
  in ``a``. 
*/
#define REDUCE_MOD3(a) \
 (a) = (((a) + (((a) >> 2) & 0x1111111111111111ULL)) & NEG_MASK_MOD3)


/** @brief Final reduction of a bit field of integers modulo 3

  We assume that an array of integers (mod 3) is stored in an
  an integer ``a`` of type ``uint64_t``. Here each entry of that
  array is stored in a filed of 4 bits.

  We assume that in each entry the lower 2 bits may be set, and
  we reduce each entry of value 3 to 0. The result is stored
  in ``a``.

*/
#define REDUCE_FINAL_MOD3(a, tmp) \
 tmp = (a) & ((a) >> 1) & 0x5555555555555555ULL; \
 (a) ^=  tmp ^ (tmp << 1)


/** @brief Expand a bit field of integers modulo 3

  We assume that an array of integers (mod 3) is stored in an
  integer ``a`` of type ``uint64_t``. Here each entry of that
  array is stored in a field of 2 bits. 

  We expand the lower 16 bit fields from a length of 2 to a
  length of 4, and store the result in ``a``.  
*/
#define EXPAND_3_15(a) \
    (a) = ((a) & 0xffffULL) \
        +  (((a) & 0xffff0000ULL) << 16); \
    (a) = ((a) & 0xff000000ffULL) \
        +  (((a) & 0xff000000ff00ULL) << 8); \
    (a) = ((a) & 0xf000f000f000fULL) \
        +  (((a) & 0xf000f000f000f0ULL) << 4); \
    (a) = ((a) & 0x303030303030303ULL) \
        +  (((a) & 0xc0c0c0c0c0c0c0cULL) << 2)

/** @brief Compress a bit field of integers modulo 3

  We assume that an array of integers (mod 3) is stored in an
  integer ``a`` of type ``uint64_t``. Here each entry of that 
  array is stored in a field of 4 bits. 

  We assume that in each entry the lower 2 bits may be set. We 
  compress the bit fields of length 4 to adjacent bit fields of
  length 2 and store the result in the lower hals of ``a``.  
*/
#define COMPRESS_15_3(a) \
    (a) = ((a) & 0x303030303030303ULL) \
        +  (((a) >> 2) & 0xc0c0c0c0c0c0c0cULL); \
    (a) = ((a) & 0xf000f000f000fULL) \
        +  (((a) >> 4) & 0xf000f000f000f0ULL); \
    (a) = ((a) & 0xff000000ffULL) \
        +  (((a) >> 8) & 0xff000000ff00ULL); \
    (a) = ((a) & 0xffffULL) \
        +  (((a) >> 16) & 0xffff0000ULL)


/// @endcond 



/*************************************************************************
*** Macros for 24 times 24 times matrices mod 3
*************************************************************************/

// %%WITH N_COL = 3


/// @cond DO_NOT_DOCUMENT 



// Add ``(-1)**sign * src`` to ``dest``.
// Here ``p_src`` and ``p_dest`` should be of type uint64_t* and point
// to rows ``src`` and ``dest`` of  matrices in **matrix mod 3**
// encoding  as documented in the header of this file. ``sign`` must
// be a variable of type uint64_t.
#define ADDROW_MOD3(p_dest, p_src, sign) \
    sign = (0 - ((sign) & ONE)) & NEG_MASK_MOD3; \
    // %%FOR* j in range(N_COL)
    (p_dest)[%{j}] += ((p_src)[%{j}] ^ (sign)); \
    REDUCE_MOD3((p_dest)[%{j}]); \
    // %%END FOR


// Copy row from ``p_src`` to ``p_dest``
#define COPYROW_MOD3(p_dest, p_src) \
    // %%FOR* j in range(N_COL)
    (p_dest)[%{j}] = (p_src)[%{j}]; \
    // %%END FOR

// Set the 64-bit integer i to 0 if row ``p_src`` of matrix is 0.
#define ROW_ISZERO(p_src, i) \
    i = (p_src)[0] ^ ((p_src)[0] >> 1); \
    // %%FOR* j in range(1, N_COL)
    i |= (p_src)[%{j}] ^ ((p_src)[%{j}] >> 1); \
    // %%END FOR
    i &= 0x1111111111111111ULL;



// obtain pointer to row ``i`` of matrix ``p_src``
#define ROW_MOD3(p_src, i)  ((p_src) + (i) * %{int:N_COL})


// obtain entry ``j`` in row ``p_src``
#define ROWENTRY_MOD3(p_src, j) \
   (((p_src)[(j) >> 4] >> (((j) & 15) << 2)) & 3)



/// @endcond



/*************************************************************************
*** Echelonize a 24 times 24 times matrices mod 3
*************************************************************************/




/// @cond DO_NOT_DOCUMENT

/** @brief Auxiliary function for function ``leech3matrix_echelon``.

   Here ``p_a`` is a submatrix of a matrix ``a`` in  **matrix mod 3**
   encoding  as documented in the header of this file. ``p_a`` should
   point to a row ``i`` of matrix ``a`` and ``p_end`` should point
   behind the last row of matrix ``a``. Then we pivot over the
   given ``column``.

   This means that we look for the first row ``k`` with a nonzero
   entry in that column. Then we perform row operations with that row
   in order to zero all aother rows >= i of the matrix. Finally, we
   exchange row ``i`` with row ``k``.
*/
static inline uint32_t pivot3(uint64_t *p_a, uint64_t *p_end, uint32_t column)
{
     
    uint64_t sign_pivot, sign, tmp;
    uint64_t  *p_pivot, *p_row;
    uint_fast32_t col_ofs = column >> 4, col_sh = (column & 15) << 2;

    for (p_pivot = p_a; p_pivot < p_end; p_pivot += %{N_COL}) {
        sign_pivot = (p_pivot[col_ofs] >> col_sh) + 1;
        if (sign_pivot & 2) goto pivot_found;
    }
    return 0;

pivot_found:
    ++sign_pivot;
    for (p_row = p_pivot + %{N_COL}; p_row < p_end; p_row += %{N_COL}) {
        sign =  (p_row[col_ofs] >> col_sh) + 1;
        if (sign & 2) {
            sign += sign_pivot;
            ADDROW_MOD3(p_row, p_pivot, sign)
        }
    }

    // %%FOR* i in range(N_COL)
    tmp = p_a[%{i}]; p_a[%{i}] = p_pivot[%{i}]; p_pivot[%{i}] = tmp;
    // %%END FOR
    return %{N_COL};
}


/// @endcond

/** @brief Echelonize a matrix of integers mod 3.

   Here ``a`` is a matrix in  **matrix mod 3** encoding as documented
   in the header of this file. That matrix is transformed to row
   echelon form. We echelonize columns 0,...,23 of matrix ``a`` in
   that order. The matrix is not converted to reduced echelon form.

   The function returns the number of rows in the echelonized matrix
   that are nonzero in columns 0,...,23.
*/

// %%EXPORT px
uint32_t leech3matrix_echelon(uint64_t *a)
{
    uint64_t *p_a = a, *p_end = a +  %{int:24*N_COL};
    uint_fast32_t col;
    for (col = 0; col < 24; ++col) {
        p_a += pivot3(p_a, p_end, col);
    }
    return (uint32_t)(((p_a - a) * %{int:1+2**24//N_COL}) >> 24);
}


/*************************************************************************
*** Change a 24 times 24 times matrix mod 3 to reduced echelonized form
*************************************************************************/


/// @cond DO_NOT_DOCUMENT




/** @brief Auxiliary function for function ``leech3matrix_reduced_echelon``.

   Here ``p_a`` is a submatrix of a matrix ``a`` in  **matrix mod 3**
   encoding  as documented in the header of this file. ``p_a`` should
   point to a row ``i`` of matrix ``a``. The function scans for the
   lowest column index ``j`` such that entry in column ``j`` of that
   row is nonzero. It possibly changes the sign of row ``i`` so that
   the entry in column ``j`` will be one. Then it zeros the entries
   in column ``j`` in the ``n_up`` rows before row ``i``  by adding
   a multiple of row ``i``.

   The function returns the column index ``j``. If the vector in
   row ``i`` is zero then the function performs no action and
   returns  %{int:N_COL << 4}.
*/
static inline uint32_t pivot3_up(uint64_t *p_a, uint32_t n_up)
{
    uint64_t v, sign, *p_up;
    uint_fast32_t i, col, n;
    for (i = 0; i < %{N_COL}; ++i) {
        v = (p_a[i] ^ (p_a[i] >> 1)) & 0x1111111111111111ULL;
        if (v) goto found;
    }
    return %{int:N_COL << 4};
found:
    col = uint64_low_bit(v);
    if ((p_a[i] >> col) & 2) {
        // %%FOR* j in range(N_COL)
        p_a[%{j}] ^= NEG_MASK_MOD3;
        // %%END FOR
    }

    p_up = p_a;
    for (n = 0; n < n_up; ++n) {
        p_up -= %{N_COL};
        sign =  (p_up[i] >> col);
        if ((sign + 1) & 2) {
            ADDROW_MOD3(p_up, p_a, sign)
        }
    }
    return (i << 4) + (col >> 2);
}


/// @endcond


/** @brief Convert matrix of integers mod 3 to reduced echelonized form.

   Here ``a`` is a matrix in  **matrix mod 3** encoding as documented
   in the header of this file. That matrix is converted to reduced row
   echelon form.  We echelonize columns 0,...,47 of matrix ``a`` in
   that order. The leading nonzero value in a row is always equal to 1.

   The function returns the set of columns used for pivoting as a bit
   field;  i.e. bit ``i`` in the returned integer is set if
   column ``i`` has been used for pivoting.

   Parameter ``d`` should usually be ``0``. In case ``d > 0`` we make
   no atttempt to zero an entry ``(i, j)`` if ``j >= d `` and the
   leading coefficient of row ``i`` is in a column with idnex ``< d``.
*/
// %%EXPORT px
uint64_t leech3matrix_reduced_echelon(uint64_t *a, uint32_t d)
{
    uint64_t *p_a = a, *p_end = a + %{int:24*N_COL}, bitmap = 0, b;
    uint_fast32_t col, row = 0;
    for (col = 0; col < 48; ++col) {
        if (col == d) row = 0;
        if (pivot3(p_a, p_end, col)) {
            b = pivot3_up(p_a, row);
            bitmap |= ONE << b;
            p_a += %{N_COL};
            ++row;
        }
    }
    return bitmap;
}




/*************************************************************************
*** Intersect kernel and image in a 24 times 24 times matrix mod 3
*************************************************************************/


/// @cond DO_NOT_DOCUMENT

/** @brief Stucture for computing intersection of kernel an image.

   Here component ``a`` is a matrix ``a`` in  **matrix mod 3**
   encoding  as documented in the header of this file.
   We consider ``a`` as a pair of two matrices ``Ah, Al``,
   with``Al`` in columns 0,...,23 and ``Ah`` in columns 24,...,47
   of ``a``.

   Som more documentation shoud be added here!!!!!!!!

*/
typedef struct {
    uint64_t *a;          // pointer to matrix
    uint8_t row_mark[24]; // No of partner row of a row or 0xff
    uint8_t col_piv[48];  // row used for pivoting a column
    uint32_t n;           // No of columns in one of the matrices
    uint32_t len_img;     // length of image matrix
    uint32_t len_isect;   // length of intersection kernel/image
} mat_mod3_type;


static inline
void _load_matrix(mat_mod3_type *m, uint64_t *a)
{
    uint64_t bitmap = leech3matrix_reduced_echelon(m->a = a, 24);
    uint32_t i, row = 0;
    memset(m->col_piv, 0xff, sizeof(m->col_piv));
    for (i = 0;  i < 48; ++i) if ((bitmap >> i) & 1) {
         m->col_piv[i] = (uint8_t)row;
         ++row;
    }
    m->len_img = mat24_bw24((uint32_t)(bitmap & 0xffffffUL));
    m->n = 24;
}




static inline void
_adjust_col(mat_mod3_type *m, uint32_t col, uint32_t ref_col, uint32_t fst_row)
{
    uint_fast32_t row = m->col_piv[col], n = m->n;
    uint_fast32_t ref_index = ref_col >> 4, ref_sh = (ref_col & 15) << 2;
    uint8_t *p_mark = m->row_mark + row;
    uint64_t *a = m->a, *p_pivot_row = ROW_MOD3(a, row);
    uint64_t *p_row = p_pivot_row, *p_fst_row = ROW_MOD3(a, fst_row);
    while (p_row > p_fst_row) {
        uint_fast32_t ref_row = *--p_mark;
        p_row -= %{N_COL};
        if (ref_row < n) {
            uint64_t x = (ROW_MOD3(a, ref_row)[ref_index] >> ref_sh) + 1;
            if (x & 2) {
                ADDROW_MOD3(p_row, p_pivot_row, x)
            }
        }
    }
}

static inline void
_compare_cols(mat_mod3_type *m, uint32_t col)
{
    uint_fast32_t n = m->n, ref_col = col + n;
    uint_fast32_t index = col >> 4, sh = (col & 15) << 2;
    uint_fast32_t ref_index = ref_col >> 4, ref_sh = (ref_col & 15) << 2;
    int_fast32_t icol = col, irow;
    uint64_t *a = m->a, *p_piv, *p_ref_piv, d = 0;
    uint8_t *p_mark;
    while (icol >= 0 && m->col_piv[icol] >= n) --icol;
    if (icol < 0) return;
    irow = m->col_piv[icol];
    p_mark = m->row_mark + irow;
    while (irow >= 0) {
        uint32_t ref_row = *p_mark;
        if (ref_row < n) {
            uint64_t x = (((ROW_MOD3(a, irow)[index] >> sh) & 3) ^ 3)
                + ((ROW_MOD3(a, ref_row)[ref_index] >> ref_sh) & 3);
            x += x >> 2;
            if ((x + 1) & 2) {
                d = x;
                p_piv = ROW_MOD3(a, irow);
                p_ref_piv = ROW_MOD3(a, ref_row);
                *p_mark = m->row_mark[ref_row] = 0xff;
                --p_mark; --irow;
                goto pivot;
            }
        }
        --p_mark; --irow;
    }
    return;

  pivot:
    while (irow >= 0) {
        uint32_t ref_row = *p_mark;
        if (ref_row < n) {
            uint64_t x = (((ROW_MOD3(a, irow)[index] >> sh) & 3) ^ 3)
                + ((ROW_MOD3(a, ref_row)[ref_index] >> ref_sh) & 3);
            x += x >> 2;
            if ((x + 1) & 2) {
                uint64_t *p_row = ROW_MOD3(a, irow);
                uint64_t *p_ref_row = ROW_MOD3(a, ref_row);
                x += d + 1;
                ADDROW_MOD3(p_row, p_piv, x)
                ADDROW_MOD3(p_ref_row, p_ref_piv, x)
            }
        }
        --p_mark; --irow;
    }
}



/** @brief Intersect kernel and image of matrix of integers mod 3.

   Here ``a = m->a`` is a matrix in **matrix mod 3** encoding as
   documented in the header of this file. That matrix must be in
   reduced echelon form as returned by the auxiliary
   function ``_load_matrix``.

   Let the parts ``Ah``, ``Al`` of ``a`, and also the output
   submatrices ``A_imag``, ``A_ker`` be defined as in
   function ``leech3matrix_kernel_image``.

   The current function changes some rows of ``A_img``, ``A_ker``,
   so that these rows will contain the intersection of the two
   matrices. If ``i`` is a row of matrix ``A_img`` then on
   return ``m->row_mark[i]`` will contain the number of a
   row in matrix ``A_ker`` equal to row ``i`` of ``A_img``.
   If now such row can be found then  ``m->row_mark[i]`` will
   contain the entry 0xff. If ``m->row_mark[i]`` contains a valid
   row ``j`` then ``m->row_mark[j]` will contain row number ``i``.

   In the end, sufficiently many equal rows of ``A_ker`` and ``A_img``
   will be computed (and marked in array ``m->row_mark``), so that
   the intersction of the row spaces spanned by the two matrices
   is known. But the rows of the two matrices will not be sorted as
   required by function ``leech3matrix_kernel_image``.
*/
static inline
void _intersect_ker_im(mat_mod3_type *m)
{
    uint_fast32_t col, n = m->n, row;
    memset(m->row_mark, 0xff, sizeof(m->row_mark));
    for (col = 0; col < n; ++col)  {
        uint32_t piv0 = m->col_piv[col];
        uint32_t piv1 = m->col_piv[col + n];
        if (piv0 < n) {
            if (piv1 < n) {
                m->row_mark[piv0] = (uint8_t)piv1;
                m->row_mark[piv1] = (uint8_t)piv0;
            } else {
                _adjust_col(m, col, col + n, 0);
            }
        } else {
            if (piv1 < n) {
                _adjust_col(m, col + n, col, m->len_img);
            } else {
                _compare_cols(m, col);
            }
        }
    }
    m->len_isect = 0;
    for (row = 0; row < m->len_img; ++row) {
         m->len_isect += m->row_mark[row] < n;
    }
}




static inline
int32_t _sort_matrix(uint64_t *a, uint8_t *marker, uint32_t n)
{
     #define BUF_LEN 24 // could be 12!!!!!!!!!!!!!!
     uint64_t buf[BUF_LEN * %{N_COL}];
     uint64_t *p_buf_fill = buf + BUF_LEN * %{N_COL};
     uint64_t *p_a_end = a + n * %{N_COL};
     uint64_t *p_a_fill = p_a_end;
     uint8_t *p_marker = marker + n;
     while (p_a_end > a) {
         p_a_end -=  %{N_COL};
         if (*--p_marker != 0xff) {
             p_buf_fill -= %{N_COL};
             if (p_buf_fill < buf) return -1;
             COPYROW_MOD3(p_buf_fill, p_a_end)
         } else {
             p_a_fill -= %{N_COL};
             COPYROW_MOD3(p_a_fill, p_a_end)
         }
     }
     memcpy(a, p_buf_fill, (p_a_fill - a) * sizeof(uint64_t));
     return 0;
}


/** @brief Reeturn rank of matrix of integers mod 3
*/
static inline
uint32_t _rank_matrix(uint64_t *a)
{
     uint32_t rk = 24;
     while (rk--) {
         uint64_t *row, value;
         row = ROW_MOD3(a, rk);
         ROW_ISZERO(row, value)
         if (value) return rk+1;
     }
     return 0;
}



/// @endcond



/** @brief Intersection of kernel and image of matrix of integers mod 3

   Here  ``a`` is a matrix in **matrix mod 3** encoding  as documented
   in the header of this file. We consider ``a`` as a pair of two
   matrices ``Ah, Al``, with ``Al`` in columns 0,...,23, and ``Ah`` in
   columns 24,...,47 of ``a``.

   We apply a sequence of row operations to the pair ``Ah, Al``, so
   that the resulting output ``Ah, Al`` has the properties stated
   below. We will write ``A_img`` for the output matrix ``Al``.

   The first ``len_img`` rows of matrix ``A_img`` are linear
   independent, and the other rows of matrix ``A_img`` are zero;
   so ``A_img`` has rank  ``len_img``.

   Define ``A_ker`` to be the submatrix of output matrix ``Ah``
   containing the rows ``len_img`` and above of that matrix. Then the
   first ``len_ker`` rows of matrix ``A_ker`` are linear independent,
   and the other rows of ``A_ker`` are zero; so ``A_ker`` has
   rank  ``len_ker``.

   The function also computes the intersection of the spaces spanned
   by the rows of matrices ``A_img`` and ``A_ker``. The intersection
   has dimension ``len_isect``; and the first ``len_isect`` rows of
   the output matrices ``A_img`` and ``A_ker`` will be equal.

   In case of success the function returns

   ``len_img  +  0x100 * len_ker  +  0x10000 * len_isect``.

   It returns -1 in case of failure. Such a failure sould be
   considered as a software bug.

   The typical use case for this function is to store an arbitrary
   matrix in ``Al``, and the unit matrix in ``Ah``. Then the function
   computes the image of input matrix ``Al`` in the first ``len_img``
   rows of ``A_img``, and the kernel of ``Al`` in the first``len_ker``
   rows of matrix ``A_ker``. As stated above, it also computes the
   intersection of the kernel and the image.
*/
// %%EXPORT px
int32_t leech3matrix_kernel_image(uint64_t *a)
{
    mat_mod3_type m;
    uint32_t len_ker;
    _load_matrix (&m, a);
    _intersect_ker_im(&m);
    if (m.len_img > m.n) return -1;
    if (_sort_matrix(a, m.row_mark, m.len_img)) return -2;
    if (_sort_matrix(ROW_MOD3(a, m.len_img), m.row_mark + m.len_img,
          m.n -  m.len_img)) return -3;
    len_ker = _rank_matrix(a) - m.len_img;
    return m.len_img + (len_ker << 8) + (m.len_isect << 16);
}




/*************************************************************************
*** Compress a 24 times 24 times matrices mod 3
*************************************************************************/


/** @brief compress a matrix in *matrix mod 3*  encoding

   Let ``a`` be an 24 times 48 matrix in *matrix mod 3*  encoding.
   We consider ``a`` as a pair of two matrices ``Ah, Al``,
   with``Al`` in columns 0,...,23 and ``Ah`` in columns 24,...,47
   of ``a``.

   We store matrix ``Al`` in the entries``v[0], ..., v[23]``, and
   matrix ``Ah`` in the entries``v[24], ..., v[47]``.
   Here column ``j`` of a row of ``Ah`` or ``Al`` is reduced
   modulo 3 (so it has value 0, 1, or 2) and that value
   is stored in bits ``2*j+1`` and ``2*j`` of the corresponding
   entry of ``v``.

   So each of the matrices ``Al`` and ``Ah`` will be  encoded as the
   part with tag 'A' of a vector in the representation \f$\rho_3\f$
   of the monster modulo 3.

   The overlapping ``v == a`` is legal; any other kind of
   overlappig between ``v`` and ``a`` is illegal.

*/
// %%EXPORT px
void leech3matrix_compress(uint64_t *a, uint64_t *v)
{
    uint64_t v0, v1, tmp, w[24];
    uint_fast32_t i, j = 0;

    for (i = 0; i < 24; ++i) {
        v0 = a[j]; tmp = a[j+1]; v1 = a[j+2];
        COMPRESS_15_3(v0);
        COMPRESS_15_3(tmp);
        COMPRESS_15_3(v1);
        v0 += (tmp & 0xffff) << 32;
        v1 = (v1 << 16) + (tmp >> 16);
        REDUCE_FINAL_MOD3(v0, tmp);
        REDUCE_FINAL_MOD3(v1, tmp);
        v[i] = v0; w[i] = v1;
        j += %{N_COL};
    }
    for (i = 0; i < 24; ++i) v[i+24] = w[i];
}



/*************************************************************************
*** subtract diagonal matrix from a 24 times 24 times matrices mod 3
*************************************************************************/

/** @brief Subtract diagonal matrix from matrix in *matrix mod 3*  encoding.

   Let ``a`` be an 24 times 48 matrix in *matrix mod 3*  encoding.
   
   We subtract a diagonal matrix from ``a``. More precisely, we 
   subtract the integer ``diag`` from all entries ``a[i, i+offset]``,
   for ``i = 0,...,23``.
*/
// %%EXPORT px
void leech3matrix_sub_diag(uint64_t *a, uint64_t diag, uint32_t offset)
{
    uint_fast32_t col_ofs, col_sh;
    uint64_t *p_a, *p_end = a + 24 * %{N_COL};
    diag %= 3;
    if (diag == 0) return;
    diag = 3ULL - diag;
    for (p_a = a; p_a < p_end; p_a += %{N_COL}) {
        col_ofs = offset >> 4, col_sh = (offset & 15) << 2;
        p_a[col_ofs] += diag << col_sh;
        REDUCE_MOD3(p_a[col_ofs]);
        ++offset;
    }
}



/*************************************************************************
*** Rank and kernel of a 24 times 24 times matrices mod 3
*************************************************************************/

/** @brief Rank and kernel of a ``24 times 24`` matrix modulo 3

   Let ``r`` be the rank of the ``24 times 24`` matrix ``b = a - d * 1``.
   Here the entries of that matrix are taken modulo 3, ``d`` is an 
   integer, and ``1`` is the unit matrix. 
   Input ``a`` is a 24 times 24 matrix in  **matrix mod 3** encoding 
   as documented in the header of this file. 

   Let ``r`` be the rank of matrix ``b`` with entries taken modulo 3.
   If matrix ``b`` has rank 23 then its kernel is one dimensional. In 
   that case the kernel contains two nonzero vectors ``+-w``, and we
   define ``w`` to be one of these vectors. Otherwise we let ``w`` be 
   the zero vector.

   The function returns the value ``(r << 48) + w``, with ``w`` the
   vector defined above given in *Leech lattice mod 3 encoding* as 
   described in *The C interface of the mmgroup project*. 

   Input ``a`` is destroyed.
*/
// %%EXPORT px
uint64_t leech3matrix_rank(uint64_t *a, uint32_t d)
{
    uint64_t i;

    // We now consider a as a pair of two matrices Ah, Al, with
    // Al in columns 0,...,23 and Ah in columns 24,...,47.
    // Store b = b - d * 1 in Al and the unit matrix 1 in Ah.
    for (i = 0; i < 72; i += 3) {
        a[i+1] &= 0xffffffffULL;
        a[i+2] = 0;
    }
    leech3matrix_sub_diag(a, d, 0);
    leech3matrix_sub_diag(a, 2, 24);
    // Echelonize the pair (Ah, Al) simultaneously, so that 
    // Al is in (non-reduced) echelon form. Then the ``24-r``
    // rows with highest indices of Ah contain the kernel of A'.
    leech3matrix_echelon(a);
    // Store Ah in the entries of ``a[24,...,27]`` and
    // Al in the entries of ``a[0,...,23]``.
    leech3matrix_compress(a, a);
    // Compute the rank of Al in i
    for (i = 24; i > 0; i -= 1) if (a[i-1]) goto rank_computed;
    i = 0;
  rank_computed:
    // Return i << 48 if i != 23
    if (i != 23) return i << 48;
    // Return (24 << 48) + w  if  i == 23. Here w is row 23 of 
    // matrix Ah converted to *Leech lattice mod 3 encoding*.
    return (23ULL << 48ULL) + xsp2co1_from_vect_mod3(a[24+23]);
}

// %%END WITH   # N_COL = 3


/*************************************************************************
*** Multiply a vector with a matrix modulo 3
*************************************************************************/




/** @brief Multiply vector with a ``24 times 24`` matrix modulo 3

   Input ``a`` is a 24 times 24 matrix encoded as the part with tag
   'A' of a vector in the representation \f$\rho_3\f$ of the monster
   modulo 3. Input ``v`` is a vector of 24 integers  modulo 3 encoded
   in **Leech lattice mod 3** encoding. The function computes the
   product \f$v \cdot a\f$ of the vector \f$v\f$ and the matrix \f$a\f$
   and returns the result in **Leech lattice mod 3** encoding.

   Vector \f$v\f$ has 24 entries. If the upper \f$k\f$ entries of
   \f$v\f$ are zero then we access the first \f$24-k\f$ rows of
   matrix \f$a\f$ only. So the buffer referred by ``a`` must have
   length (24 - k) in this case.
*/
// %%EXPORT px
uint64_t leech3matrix_vmul(uint64_t v, uint64_t *a)
{
    uint64_t ac = 0, m_and, m_xor, r, t;

    v ^= (v >> 24) & 0xffffffULL;
    v &= 0xffffffffffffULL;
    while (v) {
        r = a[0];
        m_and = 0ULL - (v & 1ULL);
        m_xor = 0ULL - ((v >> 24) & 1ULL);
        r = (r ^ m_xor) & m_and;
        // compute carries for mod-3 addition of r and ac in t
        t = ac & r;
        t |= ((t << 1) & (ac ^ r));
        t &= 0xaaaaaaaaaaaaaaaaULL;
        // ac += r; subtract 3 from entries where a carry occurs 
        ac = ac + r - t - (t >> 1);
        a += 1;
        v = (v >> 1) & 0x7fffff7fffffULL;
    }
    return xsp2co1_from_vect_mod3(ac);
}


/*************************************************************************
*** Finding type-4 vectors in subspace of Leech lattice mod 3
*************************************************************************/

/** @brief Prepare subspace of Leech lattice mod 3 for finding type-4 vectors

    Let \f$a\f$ be the subspace of the Leech lattice mod 3 spanned by
    the vectors in the array ``a`` of length ``n``. Here each entry of
    the array ``a`` is encoded in the same way as a row of the part
    with tag 'A' of a vector in the representation \f$\rho_3\f$ of the
    Monster modulo 3. Usually, such a subspace of the Leech lattice
    mod 3 is computed by applying function ``leech3matrix_echelon`` to
    a (suitably modified) part with tag 'A' of a vector in the
    representation \f$\rho_3\f$.

    The function computes an array of ``2*n`` random vectors taken
    from the space \f$a\f$ and stores these ``2*n`` vectors in the
    array ``w`` in  **Leech lattice mod 3** encoding. Half of the
    vectors in array ``w`` are obtained by left multiplying
    matrix \f$a\f$ with a random upper triangular matrix; and the
    other half of these vectors is obtained by left multiplication
    with a random lower triangular matrix. Parameter ``seed`` points
    to a random generator for generating random matrices; see 
    module ``gen_random.c`` for details.

    Thus the vectors in array ``w`` span the space \f$a\f$; and we
    may obtain random vectors in \f$a\f$ by performing random
    additions and subtractions of the entries of ``w``. E.g.
    function ``leech3matrix_prep_type4`` generates random type-4
    in the space space \f$a\f$ using that method.

    The function returns the size ``2*n`` of the array ``w`` in case
    of success and a negative value in case of failure. Any
    overlapping between the arrays ``a`` and ``w`` is allowed. On
    input, ``1 <= n <= 12`` must hold.
*/
// %%EXPORT px
int32_t leech3matrix_prep_type4(uint64_t *a, uint32_t n, uint64_t *w, uint64_t *seed)
{
     uint64_t sp[12], v;
     uint_fast32_t i, j, stage, d;
     uint8_t f[66];
     if (n > 12 || n == 0) return -1;
     for (i = 0; i < n; ++i) sp[i] = a[i];
     for (stage = 0; stage < 2; ++stage) {
         if (gen_rng_bytes_modp(3, f, (n*(n-1)) >> 1, seed)) return -1;
         d = 0;
         for (i = 0; i < n; ++i) {
             v = ((uint64_t)1) << i;
             for (j = 0; j < i; ++j) {
                 v += (f[d+j] & 1) + ((uint64_t)(f[d+j] & 2) << 23);
             }
             d += i;
             *w++ = leech3matrix_vmul(v, sp);
         }
         for (i = 0; i + i < n; ++i) {
             v = sp[i]; sp[i] = sp[n - i - 1]; sp[n - i - 1] = v;
         }
     }
     return n+n;
}



/** @brief Random type-4 vector in subspace of Leech lattice mod 3

    The function tries to find a random type-4 vector in a
    subspace \f$a\f$ of the Leech lattice mod 3 spanned by the
    vectors in the array ``a`` of length ``n``. Here the entries
    of the array ``w`` should be given
    in **Leech lattice mod 3 encoding**,
    as e.g. returned by function ``leech3matrix_prep_type4``.
    That function returns more vectors generating the
    space \f$a\f$ than necessary in order to facilitate the
    generation of random vectors in \f$a\f$.

    The function performs up to ``trials`` random additions
    or subtractions in the space  \f$a\f$, until it finds
    a type-4 vector. If such a type-4 vector has been found then
    that vector is returned as a vector ``v`` in the Leech lattice
    mod 2 in **Leech lattice encoding**. Parameter ``seed`` points
    to a random generator for generating the required random data;
    see module ``gen_random.c`` for details.

    If a type-4 vector ``v`` has been found then the function
    returns ``(t << 4) + v``. Here ``0 <= v < 0x1000000`` is the
    vector found in the Leech lattice mod 2
    in **Leech lattice encoding**; and ``t`` is the number of
    trials required to find ``v``. In case ``t > 127`` we
    put ``t = 127``.
   
    If no type-4 vector has been found after ``trials`` trials
    then the function returns 0.

    The function returns a negative value in case of failure;
    e.g. if the random generator has failed.
*/
// %%EXPORT px
int32_t leech3matrix_rand_type4(uint64_t *w, uint32_t n, uint32_t trials, uint64_t *seed)
{
     uint64_t v, k, t = 0;
     uint_fast32_t i, i1;
     int32_t res;
     for (i = 0; i < trials ; ++i) {
         k = res = gen_rng_modp(n, seed);
         if (res < 0) return -1;
         v = w[n - 1], w[n - 1] = w[k]; w[k] = v;
         k = res = gen_rng_modp((n - 1) << 1, seed);
         if (res < 0) return -1;
         v = w[k >> 1] ^ (0 - (k & 1));
         w[n - 1] = v = gen_leech3_add(w[n - 1], v);
         t = gen_leech3to2(v);
         if ((t >> 24) == 4) {
             t  &= 0xffffff;
             i1 = i > 0x7e ? 0x7f : i + 1;
             return (int32_t)(i1 << 24) + (int32_t)t;
         }
     }
     return 0;
}




/*************************************************************************
*** Functions for bit matrices
*************************************************************************/







/**
 @brief Add an equation to a system of linear bit equations
 
 The idea behind this function is that an external process generates
 rows of a bit matrix with ``ncols`` columns, with ``0 < ncols <= 32``.
 This function checks such a row ``a`` and accepts it, if it linearly
 independent of all previously accepted rows. Thus at most ``ncols``
 rows can be accepted. The ``nrows`` already accepted rows are  stored
 in the array ``m``. The function returns  ``1`` if row ``a`` is
 accepted and ``0``  otherwise. A negative return value indicates
 an error. The size of the array ``m`` should be at least ``ncols``.
 
 Let ``A`` be the ``ncols`` times ``ncols`` matrix of all accepted
 rows ``a[i]``, ``0 <= i < ncols``; and let  ``I`` be the ``ncols``
 time ``ncols`` unit matrix. We left multiply ``A`` with a
 matrix ``T`` such that ``T * A = I``. Thus ``T = A**(-1)``.
 Technically, we perform row operations on the matrix ``A[:nrows]``
 containing the first ``nrows`` lines already accepted, such
 that ``T * A[:rnows]`` is in **reduced echelon form**. We also
 perform the same row operations on the unit matrix to obtain ``T``.
 We store ``T[:rnows]`` in columns ``0,...,ncols-1`` of matrix ``M``
 and ``T*A[:rnows]`` in columns ``ncols,...,2*ncols-1`` of
 matrix ``M``.
 
 One may use function ``leech2matrix_solve_eqn`` for solving a
 system of linear equations obtained in that way.
*/
// %%EXPORT px
int32_t leech2matrix_add_eqn(uint64_t *m, uint32_t nrows, uint32_t ncols, uint64_t a)
{
    // Our general strategy is to keep the matrix ``TA``in the upper
    // columns of ``m`` in reduced echelon form after the insertion  
    // of a vector ``a``. Therefore we apply row operations to ``TA``. 
    // When entring the i-th row, we also enter the i-th row of the
    // unit matrix ``I`` into the matrix stored in the lower ``ncols``
    // columns of ``m``. Then subsequent row operations apply to both,
    // the upper and the lower columns of matrix ``m``.

    uint_fast32_t row, col;       // Counters for rows and columns of ``TA``
    uint_fast32_t a_row = nrows;  // Row where to insert the (pivoted) ``a``
    uint64_t mask = ONE << ncols; // Mask for column ```col`` of ``TA``
    uint64_t a_mask = 0 - ONE;    // Mask for lowest bit of (pivoted) ``a``,
                                  // (-1) means 'no such bit found'
    // Check buffer overflow
    if (ncols > 32 || nrows > ncols) return ERR_QSTATE12_BUFFER_OVFL;
 
    // Shift vector ``a`` into the position for entering it into ``TA``.
    // Store row ``nrows`` of the unit matrix in the lower columns of ``a``.
    a = ((a & ((ONE << ncols) - 1)) << ncols) | (ONE << nrows);
 
    // Run through the columns of ``TA``. If a row of ``TA`` has a 
    // lowest bit in that column then pivot ``a`` with that row.
    // If ``a`` has a lowest bit set in that column (after pivoting)
    // then set ``a_mask`` appropriately to indicate that column.
    for (col = row = 0; col < ncols && row < nrows; ++col) {
        if (m[row] & mask) {
            a ^= (a & mask) ? m[row] : 0; 
            ++row;
        } 
        else if (a & mask & a_mask) {
            a_row = row; a_mask = mask;
        }            
        mask <<= 1;        
    }
    // All rows of ``TA`` done. Proceed with remaining columns as above.
    for ( ; col < ncols && a_mask == (0 - ONE); ++col) {
        if (a & mask) a_mask = mask; 
        mask <<= 1;        
    }
    
    // Return 0 if no bit is set in the (pivoted) ``a``.
    if (a_mask == (0 - ONE)) return 0;
    
    // Insert the pivoted ``a`` into the correct row of ``TA``
    for (row = nrows; row > a_row; --row)  m[row] = m[row-1];
    m[a_row] = a;
    
    // Pivot the lower rows of ``TA`` with ``a``.
    for (row = 0; row < a_row; ++row) {
        m[row] ^=  (m[row] & a_mask) ? a : 0;
    }    
    return 1;     
}



/**
 @brief Solve a system of linear bit equations
 
 Let ``A`` be a nonsingular  ``ncols`` times ``ncols`` bit matrix
 stored in the array ``m`` in the special form as described in 
 function ``leech2matrix_add_eqn``.
 
 The function returns the solution ``w`` of the equation
 ``w * A = v``.

 Caution:

 Here ``m`` is of of type ``uint32_t *``, but the corresponding
 parameter in function ``leech2matrix_add_eqn`` is of type
 ``uint64_t *``. This simplifies the use of this function in
 most pplications. 
  
*/
// %%EXPORT px
uint32_t leech2matrix_solve_eqn(uint32_t *m, uint32_t ncols, uint64_t v)
{
    uint_fast32_t row = 0;
    uint64_t mask = ONE, w = 0;
    
    for (row = 0; row < ncols; ++row) {
        w ^=  (v & mask) ? m[row] : 0; 
        mask <<= 1;
    }
    return  (uint32_t)(w & (mask - 1));     
}






/*************************************************************************
** Basis of a subspace of the Leech lattice modulo 2
*************************************************************************/

/// @cond DO_NOT_DOCUMENT 

/** @brief  Workhorse for function ``leech2_matrix_basis``

  This function does the job of function ``leech2_matrix_basis``
  except for the final echelonization of the basis.
*/
static inline uint32_t 
get_leech2_basis(uint32_t *v2, uint32_t n, uint64_t *basis, uint32_t d)
{
    uint32_t i, j, w, k = 0;
    uint8_t pos[24];

    // Compute a basis of the space generated by  v2[0],...,v2[n-1]  in 
    // basis[0],...,basis[k-1]. Store index of the least significant
    // bit of the i-th basis vector in pos[i].
    // Put mask[i] = 1 << pos[i].
    // Set bit m in 'bitmask' if m is an entry in array pos[0,...,k-1].
    for (i = 0; i < n; ++i) {
        w = v2[i] & 0xffffffUL;
        for (j = 0; j < k; ++j) {
             w ^= (0 - ((w >> pos[j]) & 1UL)) & basis[j];
        }
        if (w == 0) continue;
        j = w & (0 - w); 
        pos[k] = (uint8_t)(mat24_def_lsbit24_pwr2(j));
        basis[k] = w;
        if (++k >= d) break;
    }
    return k;    
}


/// @endcond 


/** @brief  Subspace generated by vectors of Leech lattice modulo 2

  Compute a basis of the subspace of the Leech lattice modulo 2
  generated by the vectors ``v2[0],...,v2[n-1]``.

  The function returns the dimension ``k`` of that subspace and
  computes a basis of that subspace in ``basis[i], 0 <= i < k``.

  Here ``d`` must be an upper bound for the dimension ``k``.
  If ``k`` is unknown, one should put ``d = 24``.

  Bits 23,...,0  of the output matrix are echelonized in a special
  way.  Here the columns are processed in the order:

  11, 22, 21, ..., 13, 12, 10, 9, ..., 1, 0, 23.

  One of the advantages of this echelonization is that the
  vector \f$\Omega\f$ (encoded as 0x800000) will occur in the
  basis if it is in the subspace, and that there are many even
  vectors (i.e. vectors orthogonal to \f$\Omega\f$) in the basis.
*/
// %%EXPORT px
uint32_t leech2_matrix_basis(uint32_t *v2, uint32_t n, uint64_t *basis, uint32_t d)
{
    uint32_t dim = get_leech2_basis(v2, n, basis, d);

    // Echelonize the final result as documented above.
    bitmatrix64_xch_bits(basis, dim, 12, 0x800);
    bitmatrix64_rot_bits(basis, dim, 1, 12,0);
    bitmatrix64_echelon_h(basis, dim, 24, 24);
    bitmatrix64_rot_bits(basis, dim, 11, 12,0);
    bitmatrix64_xch_bits(basis, dim, 12, 0x800);
    return dim;    
}



/*************************************************************************
*** Orthogonal complement in Leech lattice mod 2
*************************************************************************/


/**
   @brief Compute standard orthogonal complement in Leech lattice mod 2

   Let \f$A = a_0\ldots, a_{k-1}\f$ be a matrix of \f$k\f$ vectors
   in the Leech lattice mod 2 stored in the array ``a``. The function
   returns a basis  \f$B = b_0\ldots, b_{23}\f$ of the Leech lattice
   mod 2 in the array ``b``, and it returns a number \f$m\f$ such that
   the vectors \f$b_m\ldots, b_{23}\f$ are a basis of the orthogonal
   complement of the space generated by the row vectors of \f$A\f$.

   If the vectors  \f$(a_0\ldots, a_{k-1})\f$ are linear independent
   then the function returns \f$m = k\f$, and vector \f$b_i, i < k\f$
   is orthogonal to all vectors  \f$a_j\f$ with \f$j \neq i\f$.

   The basis \f$B = b_0\ldots, b_{23}\f$ is stored in the array ``b``.

   We require \f$k \leq 24\f$. The function returns \f$m \geq 0\f$
   in case of success a negative value in case of failure.
*/
// %%EXPORT px
int32_t leech2_matrix_orthogonal(uint64_t *a, uint64_t *b, uint32_t k)
{
   uint64_t x;
   uint32_t i, m;

   if (k > 24) return ERR_QSTATE12_PARAM;

   // We store a 24 times k matrix Bh in columns 24,...,24+k-1 of 
   // the array b and a 24 times 24 matrix Bl in columns 0,...,23
   // of the array b.

   // Put Bl = A^T (with A^T the transposed matrix of A)
   bitmatrix64_t(a, k, 24, b);

   // Let Q be the scalar product matrix for the Leech lattice mod 2.
   // Put Bh = Q * A^T, i.e. exchange row i of A^T with row i+12.
   for (i = 0; i < 12; ++i) {
       x = b[i]; b[i] = b[i+12] << 24; b[i+12] = x << 24;
   }

   // Store the unit matrix in Bl 
   for (i = 0; i < 24; ++i)  b[i] |= 1ULL << i;

   // Echelonize Bh. This corresponds to left multiplication with a
   // nonsingular matrix B. W also multiply Bl (containing the unit
   // matrix) with B. So we have  Bl = B, Bh = B * Q * A^T,  and Bh 
   // is echelonized, containing m nonzero rows  and 24 - m zero rows. 
   // Thus B is the result, with the orthogonal complement of A in 
   // rows m,...,23 of B.  
   //
   // Remark: If the rows of A are linear independent then the upper
   //         k rows of  B * Q * A^T  form a unit matrix.
   m = bitmatrix64_echelon_l(b, 24, 24, k);

   // Output B = Bl and return m
   for (i = 0; i < 24; ++i) b[i] &= 0xffffffUL;
   return m;
}


/*************************************************************************
** Radical of a subspace of the Leech lattice modulo 2
*************************************************************************/

/** @brief Radical of subspace generated by vectors of Leech lattice mod 2

  Compute the radical of the subspace of the Leech lattice modulo 2
  generated by the vectors ``v2[0],...,v2[n-1]``. Here the radical
  is the intersection of the space generated by ``v2[0],...,v2[n-1]``
  with the orthogonal complement of that space.

  Input parameters ``v2, n,`` and ``d`` are as in
  function ``leech2_matrix_basis``. A basis of the radical
  of the space is computed in ``basis``. The basis is echelonized
  as in function ``leech2_matrix_basis``. The function returns the
  dimension ``k`` of radical spanned by that basis.
*/
// %%EXPORT px
uint32_t leech2_matrix_radical(uint32_t *v2, uint32_t n, uint64_t *basis, uint32_t d)
{
    uint64_t span[24], ortho[24];
    int_fast32_t dim, i, res;

    dim = get_leech2_basis(v2, n, span, d);
    if (dim < 0) return dim;
    leech2_matrix_orthogonal(span, ortho, dim);
    bitmatrix64_echelon_h(span, dim, 24, 24);
    bitmatrix64_echelon_h(ortho + dim, 24 - dim, 24, 24);
    res = bitmatrix64_cap_h(span, ortho + dim, dim, 24 - dim, 24, 24);
    if (res < 0) return res;
    for (i = 0; i < res; ++i) basis[i] = span[i + dim - res];

    // Echelonize the final result as documented above.
    bitmatrix64_xch_bits(basis, res, 12, 0x800);
    bitmatrix64_rot_bits(basis, res, 1, 12,0);
    bitmatrix64_echelon_h(basis, res, 24, 24);
    bitmatrix64_rot_bits(basis, res, 11, 12,0);
    bitmatrix64_xch_bits(basis, res, 12, 0x800);
    return res;
}

/*************************************************************************
** List vectors in a subspace of the Leech lattice modulo 2
*************************************************************************/


/** @brief List vectors in a subspace of the Leech lattice modulo 2

  The function computes all ``2**dim`` vectors of the subspace ``V`` 
  of the Leech lattice modulo 2 given by the basis

  ``basis[0], ..., basis[dim - 1]``  .

  These vectors are written into the array ``v2``. The function
*/
// %%EXPORT px
uint32_t leech2_matrix_expand(uint64_t *basis, uint32_t dim, uint32_t *v2)
{
    int_fast32_t i, j, len = 1;
    v2[0] = 0;
    for (i = dim - 1; i >= 0; --i) {
         uint32_t w = (uint32_t)(basis[i]) & 0xffffff;
         for (j = 0; j < len; ++j) v2[len + j] = w ^ v2[j];
         len += len;
    } 
    return len;
}




/*************************************************************************
** Map Leech vector in the rep of the Monster mod 3 to signs
*************************************************************************/

/**
@brief Map vector in rep of the Monster mod 3 to array of signs

Let ``v`` be a part of a vector of the 198884-dimensional
representation of the monster group modulo 3, which is organized
as a ``n`` times ``24`` matrix of integers mod 3. Here ``v`` is
the relevant part of a vector encoded as in the ``mmgroup.mm_op``
extension; see *The C interface of the mmgroup project*,
section *Description of the mmgroup.mm extension* for details.

Let ``mult`` be  a vector  of 24 integers mod 3 encoded in
the **Leech lattice mod 3** encoding.

The function computes the scalar product of each row of ``v``
with ``mult`` and stores the ``n`` signs of these products
in the array ``sign``. Here the signs are stored in natural order
and encoded as in function ``qstate12_to_signs``  in
module ``qstate12io.c``. As usual, the integers 0, 1, and 2 (mod 3)
are mapped to 0, '+', and '-', respectively.

Output array ``signs`` should have at least ``(n + 31) >> 5``
entries.
*/
// %%EXPORT px
void leech3_vect_mod3_to_signs(uint64_t *v, uint64_t mult, uint32_t n, uint64_t *signs)
{
    uint64_t and_mask, xor_mask, w;
    uint32_t i;

    mult = xsp2co1_to_vect_mod3(mult);
    and_mask = (mult ^ (mult >> 1)) & 0x555555555555ULL;
    and_mask |= and_mask << 1;
    xor_mask = (mult & 0xaaaaaaaaaaaaULL);
    xor_mask |= xor_mask >> 1;

    for (i = 0; i < ((uint64_t)(n) + 31) >> 5; ++i) signs[i] = 0;
    for (i = 0; i < n; ++i) {
        w = (v[i] ^ xor_mask) & and_mask;
        w %= 3; w = (0x34 >> (2*w)) & 3;
        signs[i >> 5] |= w << ((i & 31) << 1);
    }

}



/*************************************************************************
*** End of of C code
*************************************************************************/


//  %%GEN h
/// @endcond  
//  %%GEN c



// %%GEN ch
#ifdef __cplusplus
}
#endif




