/** @file involutions.c
  File ``involutions.c`` contains  functions for transforming
  involutions of the  subgroup \f$G_{x0}\f$ 
  (of structure \f$2^{1+24}.\mbox{Co}_1\f$)  of the monster.

  We try to transform such involutions to a standard form 
  via conjugation by elements of the monster group. 
*/


/*************************************************************************
** External references 
*************************************************************************/

/// @cond DO_NOT_DOCUMENT 
#include <string.h>
#include "mat24_functions.h"
#define MMGROUP_GENERATORS_INTERN
#include "mmgroup_generators.h"
#define CLIFFORD12_INTERN
#include "clifford12.h"
/// @endcond  


// %%EXPORT_KWD CLIFFORD12_API


// %%GEN ch
#ifdef __cplusplus
extern "C" {
#endif
// %%GEN c


//  %%GEN h
/// @cond DO_NOT_DOCUMENT 
//  %%GEN c


/// @cond DO_NOT_DOCUMENT 


/**
  @brief Return 0 if the square of a 24 times 24 matrix is zero

  Here ``m`` is a 24 times 24 bit matrix. The function returns 0 
  if the square of ``m`` is zero and a nonzero value otherwise.

*/
static inline uint64_t square_mat24_nonzero(uint64_t *m)
{
    uint_fast32_t i, j; 
    uint64_t mi, mo, result;
    result = 0;
    for (i = 0; i < 24; ++i) {
         mi = m[i]; mo = 0;
         for (j = 0; j < 24; ++j) {
             mo ^= (0 - ((mi >> j) & ONE)) & m[j];
         }
         result |= mo;
    }
    return result & 0xffffff;
}



/**
  @brief Return type of Leech lattice vector mod2

  Here ``v`` is a vector in the Leech lattice mod 2. The function
  returns the type of ``v`` modulo 2.

*/
static inline uint64_t leech_type_mod2(uint64_t v)
{
    uint64_t x = v;
    x &= (x >> 12);
    x ^= x >> 6; 
    x ^= x >> 3;
    return (0x69ULL >> (x & 7)) & 1;
}

/// @endcond 




/*************************************************************************
*** Orthogonal complment in Leech lattice mod 2
*************************************************************************/


/**
   @brief Compute standard orthogonal complment in Leech lattice mod 2

   Let \f$A = a_0\ldots, a_{k-1}\f$ be a matrix of \f$k\f$ vectors
   in the Leech lattice mod 2 stored in the array ``a``. The function
   returns a basis  \f$B = b_0\ldots, b_{23}\f$ of the Leech lattice
   mod 2 in the array ``b``, and it returns a number \f$m\f$ such that
   the vectors \f$b_m\ldots, b_{23}\f$ are a basis of the orthogonal
   complement of the space generated by the row vectors of \f$A\f$.

   If the vectors  \f$(a_0\ldots, a_{k-1})\f$ are linear independent
   then the function returns \f$m = k\f$, and vector \f$b_i, i < k\f$
   is orthogonal to all vectors  \f$a_j\f$ with \f$j \neq i\f$.

   The basis \f$B = b_0\ldots, b_{23}\f$ is stored in the array ``b``.

   We require \f$k \leq 24\f$. The function returns \f$m \geq 0\f$
   in case of success and  -1 in case of failure.
*/
// %%EXPORT px
int32_t xsp2co1_orthogonal_complement(uint64_t *a, uint64_t *b, uint32_t k)
{
   uint64_t x;
   uint32_t i, j, m;

   if (k > 24) return -1;

   // We store a 24 times k matrix Bh in columns 24,...,24+k-1 of 
   // the array b and a 24 times 24 matrix Bl in columns 0,...,23
   // of the array b.

   // Put Bh = A^T (with A^T the transposed matrix of A)
   for (i = 0; i < 24; ++i) {
       x = 0;
       for (j = 0; j < k; ++j) x |= ((a[j] >> i) & 1) << j;  
       b[i] = x << 24;    
   }

   // Let Q be the scalar product matrix for the Leech lattice mod 2.
   // Put Bh = Q * A^T, i.e. exchange row i of Bh with row i+12.
   for (i = 0; i < 12; ++i) {
       x = b[i]; b[i] = b[i+12]; b[i+12] = x;
   }

   // Store the unit matrix in Bl 
   for (i = 0; i < 24; ++i)  b[i] |= 1ULL << i;

   // Echelonize Bh. This corresponds to left multiplication with a
   // nonsingular matrix B. W also multiply Bl (containing the unit
   // matrix) with B. So we have  Bl = B, Bh = B * Q * A^T,  and Bh 
   // is echelonized, containing m nonzero rows  and 24 - m zero rows. 
   // Thus B is the result, with the orthogonal complement of A in 
   // rows m,...,23 of B.  
   //
   // Remark: If the rows of A are linear independent then the upper
   //         k rows of  B * Q * A^T  form a unit matrix.
   m = bitmatrix64_echelon_l(b, 24, 24, k);

   // Output B = Bl and return m
   for (i = 0; i < 24; ++i) b[i] &= 0xffffffUL;
   return m;
}


/*************************************************************************
*** Invariants of an invloution in G_x0 / Q_x0
*************************************************************************/



/**
   @brief Compute invariante spaces for an involution in G_x0

   TODO: Documentation yet to be improved!!!


   Let \f$g\f$ be the element of the group \f$G_x0\f$ stored in the
   array given by parameter ``elem``. Let \f$\Lambda_2\f$ be the
   Leech lattice mod 2, with vectors in \f$\Lambda_2\f$ coded
   in **Leech lattice encoding** as usual. Conjugation by \f$g\f$ ia a
   linear operation on  \f$\Lambda_2\f$, since the vectors
   in \f$\Lambda_2\f$ correspond to the elements of the normal
   subgroup \f$Q_x0\f$ of structure \f$2^{1+24}\f$ (modulo the
   centre of \f$G_x0\f$). Let \f$A = A(g)\f$ be the \f$24 \times 24\f$
   bit matrix that performs thist operation on \f$\Lambda_2\f$ by
   right multiplication. Put  \f$A_1 = A - 1\f$.

   In this function we require \f$A^2 = 1\f$, otherwise the
   function fails. Then  \f$A_1^2 = 0\f$ and we have 

   \f$(\ker A_1)^\perp = \im A_1 \subset \ker A_1 = (\im A_1)^\perp\f$. 

   Any element \f$v \in \ker A_1\f$ is invariant under \f$g\f$, and so
   the corresponding element in \f$Q_x0\f$ is invariant up to sign.
   The elements of \f$Q_x0\f$ invariant under  \f$g\f$ (modulo
   the center of \f$Q_x0\f$) form a subspace\f$(\ker A_1)^+\f$ 
   of \f$\ker A_1\f$ of codimension \f$0\f$ 0 or \f$1\f$. 
   Let  \f$(\im A_1)^+\f$ be the orthogonal complement 
   of  \f$(\ker A_1)^+\f$. Then  \f$(\im A_1)\f$ has the
   same codimension in  \f$(\ker A_1)^+\f$. The purpose of this
   function is to compute the smaller of the two 
   spaces  \f$(\im A_1)^+\f$ or \f$\ker A_1\f$.

   We use the follwing column bits of the output matrix
    
   23,...,0:   Basis vector \f$v_i\f$ of \f$\im A_1\f$ or \f$(\im A_1)^+\f$

   55,...,32:  Preimage (under \f$A_1\f$) of basis vector \f$v_i\f$,
               undefined if \f$v_i \notin \im A\f$
   
   28:         A nozero bit in row 0 indicates an error.
   

   In bits 24,...,26  of the output matrix we return the following 
   linear forms of the basis vectors:

   Case 1:  \f$\im A_1 = (\im A_1)^+  \cap \ker A_1 \f$

   Then we return a basis of \f$\im A_1\f$.
   
   Bit 26:    0

   Bit 25:    type of basis vector (modulo 2).

   Bit 24:    sign of basis vector in \f$\im A_1\f$

   Case 2:  \f$\im A_1 \neq (\im A_1)^+  \cap \ker A_1 \f$

   Then we return a basis of \f$(\im A_1)^+\f$.

   Bit 26:    0 iff basis vector  is in \f$\im A_1\f$

   Bit 25:    0 

   Bit 24:    sign of basis vector if vector is in \f$ \im A_1\f$
              type of basis vector (mod 2) otherwise


   Bits 26,...,0  are  echelonized, so that bit 26 may be set in
   row 0 only.

   TODO: document special eclenomization of basis vector!!!
 
   Parameter ``invar`` must be an array of length 12. Zero lines are
   appeded to that array so that its length will be 12.
*/
// %%EXPORT px
int32_t xsp2co1_involution_invariants(uint64_t *elem, uint64_t *invar)
{
    uint64_t data[40], *pa = data + 16;
    uint64_t x, t0, t1;
    uint_fast32_t i, n;
    int_fast32_t status;

    // Initialize output with zeros and an error bit in row 0
    invar[0] = 0x8000000;
    for (i = 1; i < 12; ++i) invar[i] = 0;

    // Let `pa` be the 24 time 24 unit matrix 1
    for (i = 0; i < 24; ++i) pa[i] = ONE << i;

    // Conjugate row vectors of unit matrix pa with element
    // and store the the matrix A of the conjugated
    // row vectors in pa.
    status = xsp2co1_xspecial_conjugate(elem, 24, pa, 0);
    if (status < 0) return status;

    // Next we store two matrices PAH, PAL in pa, with PAL
    // in the lower 32 columns and PAH in the higher 32 columns
    // Put PAH = 1, PAL = A_1, where A_1 = A - 1 
    for (i = 0; i < 24; ++i) {
         pa[i] &=  0xffffffULL;
         pa[i] ^= 0x100000001ULL  << i;
    }

    // The group element `elem` is an involution (modulo the group  
    // Co_1) iff we have A_1**2 == 0. Otherwise we abort with an error.
    if (square_mat24_nonzero(pa)) return -1; 

    // Echelonize PAL. So we left multiply both, PAH and PAL with a 
    // nonsingular matrix T auch that T * A_1 is echelonized. Then
    // PAH will contain T and PAL will contain  T * A_1.
    // The upper n rows of PAL will contain the image \im A_1
    // The upper n rows of PAH will contain preimages of the rows of PAL
    // The lower 24 - n rows of PAH will contain the kernel \ker A_1
    // The lower 24 - n rows of PAL will be zero
    n = bitmatrix64_echelon_h(pa, 24, 24, 24);

    // Deal with the A_1 == 0, i.e. `elem` is in O_2(G_x0) or,
    // equivalently, `elem` is neutral modulo Co_1.
    if (n == 0) {
        x = xsp2co1_xspecial_vector(pa);
        if (x == 0) {
             *invar = 0;
             return 0;
        }
        x ^= leech_type_mod2(x) << 24;
        x ^= 0x6000000;
        invar[0] = x;
        return 1;
    }
      
    if (n == 8) {
        // Deal with a 2A involution in Co_1

        // Move \ker A_1 to PAL and compute signs for \ker A_1
        bitmatrix64_rot_bits(pa + 8, 16, 32, 64, 0);
        status = xsp2co1_xspecial_conjugate(elem, 16, pa + 8, 1);
        if (status < 0) return status;

        // Make sure that at most the first row of \ker A_1
        // has negative sign
        bitmatrix64_echelon_h(pa+8, 16, 25, 1);

        // Copy the image \im A_1 to output rows t1,...,t1+7, with
        // t1 = 0 if all entries of  \ker A_1 have positive sign
        // and t1 = 1 otherwise.
        t1 = (pa[0] >> 24) & 1;
        for (i = 0; i < 8; ++i) invar[t1 + i] = pa[i];

        // Skip the following steps for n == 8 in case t1 = 0.
        if (t1 == 0) goto final_echelonize;

        // Now the first row vector of the matrix PAL[8..23] 
        // representing \ker A_1 has negative sign and the 
        // other row vectors of that matrix have positive sign.


        // Comupute the orthogonal complement (\im A_1)^+  of the 
        // positive part (\ker A_1)^+ of \ker A. We also compute the
        // orthogonal complement of \ker A_1 (which is \im A_1) in
        // such a way that we can find an vector in (\im A_1)^+
        // that is not in \im A_1. 
        xsp2co1_orthogonal_complement(pa, data, 16);
        // Now we have computed a basis V of the Leech lattice mod 2
        // (in the array ``data``) such that V[16],...V[23] spans
        // the orthogonal complement \im A_1 of \ker A_1. By
        // definition of function ``xsp2co1_orthogonal_complement`` 
        // the vector v0 = V[0] is orthognal to (\ker A_1)^+, 
        // but not to  \ker A_1. 

        // Thus v0 is in  (\im A_1)^+ but not in \im A_1.
        // Copy the v0 to the output 0.
        invar[0] = data[0];

        // Set bits 25 and 26 of row i to 1 if i == 0 and to 0 otherwise.
        invar[0] |= 0x6000000;

        // Set bit 24 of output row 0 to t0, with t0 = type(v0) (mod 2).
        t0 = leech_type_mod2(invar[0]);
        invar[0] |= t0 << 24;

        // Set bit 24 of the other output rows i = 1,...8 to t[i] to
        // t[i] = t0 + type(v0 + x[i])   (mod 2) .
        // Here x[i] is the output vector in row i.
        for (i = 0; i < 8; ++i) {
            t1 = t0 ^ leech_type_mod2(invar[0] ^ invar[i]);
            invar[i] |= t1 << 24; 
        }

        // Adjust number of output rows to 9.
        n = 9;
    } else if (n == 12) {
        // Deal with a 2B or 2C involution in Co_1

        // Copy the image the \im A_1 to the array ``data`` and 
        // store the signs of these images in bit 24.
        for (i = 0; i < 12; ++i) data[i] = pa[i];
        status = xsp2co1_xspecial_conjugate(elem, 16, data, 1);
        if (status < 0) return status;

        // Copy vectors pa[0,...,11] (containing \im A_1 and preimages
        // of these images) to output vector bits 23...0 and 55...32 
        // Copy signs of images to output vector bit 24
        // Copy type(output vector) modulo 2 to output vector bit 25.
        for (i = 0; i < 12; ++ i) {
             invar[i] = (pa[i] & 0xffffff00ffffffULL)
                     | (data[i] & 0x1000000)
                     | (leech_type_mod2(pa[i]) << 25);
        }
    } else {
        // Report failure
        return -1;
    }


final_echelonize:
    // Echelonize the final result
    // Comment this later!!
    bitmatrix64_xch_bits(invar, n, 12, 0x800);
    bitmatrix64_rot_bits(invar, n, 1, 12,0);
    bitmatrix64_echelon_h(invar, n, 26, 26);
    bitmatrix64_rot_bits(invar, n, 11, 12,0);
    bitmatrix64_xch_bits(invar, n, 12, 0x800);

    // Zero preimage in row 0 if bit 26 in row 0 is set.
    invar[0] &= ((invar[0] & 0x4000000) << 2) - 1;
    return n;
    
}





/*************************************************************************
*** Application of invariants of an invloution in G_x0 / Q_x0
*************************************************************************/

/**
   @brief Compute some orthogonal complement for involution invariants

   TODO: document this!!!

   Preiminary!! This is subject to change. 

   Here parameter ``invar`` must be an output of
   function ``xsp2co1_involution_invariants``. 

   The function computes an orthoginal complement of a linear form
   stored in input ``invar`` under the Wall parametrization.

   In case ``col`` = 0, 1 we use the linear form in column
   24, 25 of input ``invar``, respectively.


   The function returns ``(uint32_t)(-1)`` in case of failure.
*/
// %%EXPORT px
int32_t xsp2co1_involution_orthogonal(uint64_t *invar, uint32_t col)
{
   uint64_t M[12], T[24], v, *pA;
   int32_t status, n, i;

   // Select column `c` of input matrix a;
   // abort if ``col`` or ``invar`` is erroneous.
   if (col > 1 || invar[0] & 0x8000000) return -1;
   col += 24;

   // Extract relevant rows of matrix a of invariants
   n = 12;
   while (n > 0 && invar[n-1] == 0) --n;
   pA = invar;
   if (pA[0] & 0x4000000) { 
       ++pA; --n;
   }
   if (n == 0) return 0;
   // Now the relevant rows of a are pA[j], 0 <= j < n;
   // Let A be the relevant part of the kernel in a
   // and P be the relevant part of the preimage of A
   // A is in columns 23,...,0 and P is in columns 55,...,32.

   // Put M = (A, P), with columns used as above.
   for (i = 0; i < n; ++i) M[i] = pA[i];
   bitmatrix64_rot_bits(M, n, 32, 64, 0);
   
   // Put T = P^T (P^T is the transposed of P)
   bitmatrix64_t(M, n, 24, T);

   // Put M = (?, A * Q), where Q is the scalar poduct in the Leech e
   // lattice  mod 2; i.e. exchange column i of A with column i + 12.
   bitmatrix64_rot_bits(M, n, 32, 64, 0); // M = (?, A)
   bitmatrix64_rot_bits(M, n, 12, 24, 0); // M = (?, A * Q)

   // Put M = A * Q * P^T
   bitmatrix64_mul(M, T, n, 24, M);

   // Put M = J, with J = ( A * Q * P^T) ** (-1);
   // abort if inverse dose not exist.
   if ((status = bitmatrix64_inv(M, n)) < 0) return status;

   // Store column `c` of input matrix a in bit vector v.
   v = 0;
   for (i = 0; i < n; ++i) v |= ((invar[i] >> col) & ONE) << i; 

   // Put v = c * J
   bitmatrix64_mul(&v, M, 1, n, &v);

   // Put v = c * J * A
   bitmatrix64_mul(&v, pA, 1, 24, &v);
   v &= 0xffffffULL;
   
   // Now v is in the space spanned by A and we have
   // v * Q * P^T = c. So v is the result
   return (int32_t) v;
}                


//  %%GEN h
/// @endcond 
//  %%GEN c


// %%GEN ch
#ifdef __cplusplus
}
#endif
